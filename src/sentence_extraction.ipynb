{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from lib.doctorailib.doctorailib import doctorai\n",
    "from lib.doctorXAIlib.doctorXAIlib import doctorXAI\n",
    "import pickle\n",
    "from lib.embedding_utils import EmbeddingUtils\n",
    "from lib.utils_similarity import UtilsSimilarity\n",
    "from lib.utils import Utils\n",
    "from lib.semantic_enrichment import SemanticEnrichment, WindowStore\n",
    "from lib.NotesCleaning import NotesCleaning\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load all the Doctor XAI and Doctor AI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_file = '../doctorXAI/models/trained_doctorAI_output/2020_9_30_MIMIC_III_.44.npz'\n",
    "dr = doctorai.DoctorAI(modelFile=model_file,\n",
    "                       ICD9_to_int_dict=\"../doctorXAI/preprocessing_doctorai/ICD9_to_int_dict\",\n",
    "                       CCS_to_int_dict=\"../doctorXAI/preprocessing_doctorai/CCS_to_int_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prendo tutte le sequenze di ICD9 generate nel preprocessing\n",
    "dataset_sequences = np.load('../doctorXAI/preprocessing_doctorai/mimic_sequences.npy',allow_pickle=True)\n",
    "#imposto il modello di doctorAI come black-box\n",
    "black_box_oracle = dr\n",
    "#seleziono il file dell'ontologia\n",
    "ontology_path_file = '../lib/doctorXAIlib/ICD9_ontology.csv'\n",
    "admission_mimic_sequences = np.load('../doctorXAI/preprocessing_doctorai/admission_mimic_sequences.npy',allow_pickle=True)\n",
    "date_mimic_sequences = np.load('../doctorXAI/preprocessing_doctorai/date_mimic_sequences.npy',allow_pickle=True)\n",
    "#per avere sottomano il significato dei vari codici\n",
    "ICD9_description_dict = pickle.load(open('../doctorXAI/ICD9_description_dict.pkl', 'rb'))\n",
    "CCS_description_dict = pickle.load(open('../doctorXAI/CCS_description_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How Doctor XAI works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#seleziono un paziente da spiegare\n",
    "patient_sequence = dataset_sequences[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drXAI = doctorXAI.DoctorXAI(patient_sequence=patient_sequence,\n",
    "                            dataset_sequences=dataset_sequences,\n",
    "                            black_box_oracle=black_box_oracle,\n",
    "                            ontology_path_file=ontology_path_file,\n",
    "                            syn_neigh_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "decision_rule, \\\n",
    "istance_string, \\\n",
    "list_split_conditions, \\\n",
    "code_names, \\\n",
    "fidelity_synth, \\\n",
    "hit_synth, \\\n",
    "features_names, \\\n",
    "labels_names, \\\n",
    "DT_synth = drXAI.extract_rule(ICD9_description_dict=ICD9_description_dict,\n",
    "                              CCS_description_dict=CCS_description_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ICD_9 = [condition.split(\" <=\")[0].split(\" >\")[0].replace(\".\", \"\") for condition in list_split_conditions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "finding_site_embedding_dict = pickle.load(open(\"../data/mapping_relations/relation_embeddings/finding_site.pkl\",'rb'))\n",
    "finding_site_dict = pickle.load(open(\"../data/mapping_relations/finding_site.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "due_to_embedding_dict = pickle.load(open(\"../data/mapping_relations/relation_embeddings/due_to.pkl\",'rb'))\n",
    "due_to_dict = pickle.load(open(\"../data/mapping_relations/due_to.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "associated_morphology_embedding_dict = pickle.load(open(\"../data/mapping_relations/relation_embeddings/associated_morphology.pkl\",'rb'))\n",
    "associated_morphology_dict = pickle.load(open(\"../data/mapping_relations/associated_morphology.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embedding_dict = pickle.load(open(\"../data/mapping_relations/relation_embeddings/description.pkl\",'rb'))\n",
    "description_dict = pickle.load(open(\"../data/mapping_relations/description.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the diabete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/only_diabete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the abbreviations dictionary\n",
    "abbreviations = pickle.load(open(\"../data/abbreviations/abbreviations_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Make a prediction and an explanation with Doctor XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diabete_df_dictionary = pickle.load(open('../data/diabete_dictionary_patient_history.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extract the most relevant part of the note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "se = SemanticEnrichment(dataset_sequences,\n",
    "                        black_box_oracle,\n",
    "                        ontology_path_file,\n",
    "                        ICD9_description_dict,\n",
    "                        CCS_description_dict,\n",
    "                        admission_mimic_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    '../data/embeddings/BioWordVec_PubMed_MIMICIII_d200.vec.bin',\n",
    "    binary=True,\n",
    "    limit=int(4E7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pickle.load(open(\"../data/icd9_mapping/mapping_icd9_description.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the information and create the dataframe with all the notes that we have to validate\n",
    "\n",
    "threshold = 95\n",
    "k = 1\n",
    "results = []\n",
    "subject_ids = [249, 1148, 1332, 2018]\n",
    "notes = []\n",
    "hadm_ids = []\n",
    "codes = []\n",
    "description_codes = []\n",
    "sub_ids = []\n",
    "\n",
    "for id in subject_ids:\n",
    "    # We get the relevant ICD9 codes for the patient and we use these codes and the relations taken from Snomed to \n",
    "    # extract the most similar parts of the notes\n",
    "    relevant_ICD9 = se.explain_and_get_most_relevant_ICD9(diabete_df_dictionary, id)\n",
    "    relevant_HADM_ID, subject_ids = se.get_relevant_HADM_ID(df, id, relevant_ICD9)\n",
    "    text, token, ICD_9 = se.get_text_and_tokens(df, relevant_HADM_ID)\n",
    "    print(relevant_ICD9)\n",
    "    best_substrings_finding_site = se.extract_most_similar_part(finding_site_dict, text, token, ICD_9, relevant_ICD9, word2vec_model, 7, threshold, k)\n",
    "    best_substrings_due_to = se.extract_most_similar_part(due_to_dict, text, token, ICD_9, relevant_ICD9, word2vec_model, 9, threshold, k)\n",
    "    best_substrings_associated_morphology = se.extract_most_similar_part(associated_morphology_dict, text, token, ICD_9, relevant_ICD9, word2vec_model, 7, threshold, k)\n",
    "    best_substrings_description = se.extract_most_similar_part(description_dict, text, token, ICD_9, relevant_ICD9, word2vec_model, 10, threshold, k)\n",
    "    \n",
    "    for hadm_id, sub_id, note, icd9_list in zip(relevant_HADM_ID, subject_ids, text, ICD_9):\n",
    "        for code in icd9_list:\n",
    "            if code in relevant_ICD9:\n",
    "                notes.append(note)\n",
    "                sub_ids.append(sub_id)\n",
    "                hadm_ids.append(hadm_id)\n",
    "                codes.append(code)\n",
    "                try:\n",
    "                    description_codes.append(mapping[str(code)])\n",
    "                except:\n",
    "                    description_codes.append(\"\")\n",
    "                    \n",
    "\n",
    "    for HADM_ID, best_substring in zip(relevant_HADM_ID, best_substrings_finding_site):\n",
    "        results.append((id, HADM_ID, \"Finding_site\", best_substring[1]))\n",
    "    for HADM_ID, best_substring in zip(relevant_HADM_ID, best_substrings_due_to):\n",
    "        results.append((id, HADM_ID, \"Due_to\", best_substring[1]))\n",
    "    for HADM_ID, best_substring in zip(relevant_HADM_ID, best_substrings_associated_morphology):\n",
    "        results.append((id, HADM_ID, \"Associated_morphology\", best_substring[1]))\n",
    "    for HADM_ID, best_substring in zip(relevant_HADM_ID, best_substrings_description):\n",
    "        results.append((id, HADM_ID, \"Description\", best_substring[1]))\n",
    "\n",
    "\n",
    "list_tuples = list(zip(sub_ids, hadm_ids, codes, description_codes, notes))\n",
    "notes_to_validate = pd.DataFrame(list_tuples, columns=['subject_id', 'hadm_id', 'codes', 'description', 'notes']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_validate.to_csv(\"../data/validation/to_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe with all the extracted relations\n",
    "\n",
    "relations = []\n",
    "similarity = []\n",
    "substrings = []\n",
    "subject_ids = []\n",
    "hadm_ids = []\n",
    "relations_type = []\n",
    "icd9_list = []\n",
    "for item in results:\n",
    "    subject_ids.append(item[0])\n",
    "    hadm_ids.append(item[1])\n",
    "    relations_type.append(item[2])\n",
    "    extracted_relations = item[3]\n",
    "    for extracted_relation in extracted_relations:\n",
    "        ICD_9 = extracted_relation[0]\n",
    "        for exr in extracted_relation[1]:\n",
    "            icd9_list.append(ICD_9)\n",
    "            relations.append(exr.relation)\n",
    "            similarity.append(exr.similarity)\n",
    "            substrings.append(exr.best_substring)\n",
    "\n",
    "list_tuples = list(zip(subject_ids, hadm_ids, icd9_list, relations_type, relations, similarity, substrings))\n",
    "\n",
    "results = pd.DataFrame(list_tuples, columns=['subject_ID', 'hadm_id', 'icd_9', 'relation_type', 'relation', 'similarity', 'extracted_substring'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/validation/result_sentence_extraction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Annotation json to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_annotations = json.load(open(\"../data/annotations.json\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HADM_ID_list = []\n",
    "substring = []\n",
    "relations = []\n",
    "SUBJECT_ID_list = []\n",
    "relations_type = []\n",
    "icd_9_codes = []\n",
    "notes = []\n",
    "start_list = []\n",
    "end_list = []\n",
    "\n",
    "for annotation in manual_annotations:\n",
    "    note = annotation['data']['TEXT']\n",
    "    ICD_9_code = annotation['data']['ICD9_CODE']\n",
    "    HADM_ID =  annotation['data']['HADM_ID']\n",
    "    subject_id = annotation['data']['SUBJECT_ID']\n",
    "    for item in annotation['annotations'][0]['result']:\n",
    "        start = item['value']['start']\n",
    "        end = item['value']['end']\n",
    "        relation = item['value']['labels'][0]\n",
    "        start = item['value']['start']\n",
    "        end = item['value']['end']\n",
    "        relations.append(relation)\n",
    "        substring.append(note[start:end+1])\n",
    "        HADM_ID_list.append(HADM_ID)\n",
    "        icd_9_codes.append(list(eval(ICD_9_code).keys())[0])\n",
    "        SUBJECT_ID_list.append(subject_id)\n",
    "        notes.append(note)\n",
    "        start_list.append(start)\n",
    "        end_list.append(end)\n",
    "\n",
    "list_tuples = list(zip(HADM_ID_list, icd_9_codes, substring, relations, start_list, end_list, notes))\n",
    "dframe = pd.DataFrame(list_tuples, columns=['HADM_ID', 'icd_9_code', 'extracted_string', 'relation', 'start', 'end', 'note'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = dframe[dframe.relation != \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.to_csv(\"../data/validation/manually_annotated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_annotated_json = dframe.to_json(orient=\"records\")\n",
    "parsed = json.loads(manually_annotated_json)\n",
    "json.dump(parsed, open(\"../data/validation/manually_annotated_dataset.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ICD9 codes and hadm id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_icd9_hadmid = pd.read_csv(\"../data/validation/simona_to_validate2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICD_9_extracted = notes_icd9_hadmid['codes']\n",
    "hadm_id_extracted = notes_icd9_hadmid['hadm_id']\n",
    "notes_extracted = notes_icd9_hadmid['notes']\n",
    "id_extracted = notes_icd9_hadmid['subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>INSURANCE.1</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Token</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Admission Date:  [**2125-2-9**]              D...</td>\n",
       "      <td>['service', 'medicine', 'allergies', 'zocor', ...</td>\n",
       "      <td>['42843', '41071', '5990', '4275', '5849', '50...</td>\n",
       "      <td>CONGESTIVE HEART FAILURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>2414</td>\n",
       "      <td>106238.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Private</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>Admission Date:  [**2186-6-7**]     Discharge ...</td>\n",
       "      <td>['date', 'birth', 'sex', 'service', 'history',...</td>\n",
       "      <td>['5781', '4280', '78039', '41401', '412', 'V45...</td>\n",
       "      <td>GASTROINTESTINAL BLEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>881</td>\n",
       "      <td>881</td>\n",
       "      <td>98046</td>\n",
       "      <td>139402.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Admission Date:  [**2198-7-17**]              ...</td>\n",
       "      <td>['date', 'birth', 'sex', 'service', 'cardiotho...</td>\n",
       "      <td>['4241', '42843', '2761', '5849', '3342', '414...</td>\n",
       "      <td>CHEST PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1088</td>\n",
       "      <td>1088</td>\n",
       "      <td>22180</td>\n",
       "      <td>116189.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Admission Date:  [**2132-9-4**]              D...</td>\n",
       "      <td>['service', 'med', 'allergies', 'patient', 're...</td>\n",
       "      <td>['53140', '2800', '4280', '53501', '25000', '4...</td>\n",
       "      <td>R/O GASTROINTESTINAL BLEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1093</td>\n",
       "      <td>1093</td>\n",
       "      <td>22180</td>\n",
       "      <td>162436.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Admission Date:  [**2134-2-16**]              ...</td>\n",
       "      <td>['service', 'medicine', 'allergies', 'patient'...</td>\n",
       "      <td>['80600', '5849', '5990', '42731', '4280', '41...</td>\n",
       "      <td>SYNCOPE;TELEMETRY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  SUBJECT_ID   HADM_ID           CATEGORY  \\\n",
       "0         293           293       28063  121936.0  Discharge summary   \n",
       "1         705           705        2414  106238.0  Discharge summary   \n",
       "2         881           881       98046  139402.0  Discharge summary   \n",
       "3        1088          1088       22180  116189.0  Discharge summary   \n",
       "4        1093          1093       22180  162436.0  Discharge summary   \n",
       "\n",
       "  INSURANCE ADMISSION_TYPE INSURANCE.1  \\\n",
       "0  Medicare      EMERGENCY    Medicare   \n",
       "1   Private      EMERGENCY     Private   \n",
       "2  Medicare      EMERGENCY    Medicare   \n",
       "3  Medicare      EMERGENCY    Medicare   \n",
       "4  Medicare      EMERGENCY    Medicare   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  Admission Date:  [**2125-2-9**]              D...   \n",
       "1  Admission Date:  [**2186-6-7**]     Discharge ...   \n",
       "2  Admission Date:  [**2198-7-17**]              ...   \n",
       "3  Admission Date:  [**2132-9-4**]              D...   \n",
       "4  Admission Date:  [**2134-2-16**]              ...   \n",
       "\n",
       "                                               Token  \\\n",
       "0  ['service', 'medicine', 'allergies', 'zocor', ...   \n",
       "1  ['date', 'birth', 'sex', 'service', 'history',...   \n",
       "2  ['date', 'birth', 'sex', 'service', 'cardiotho...   \n",
       "3  ['service', 'med', 'allergies', 'patient', 're...   \n",
       "4  ['service', 'medicine', 'allergies', 'patient'...   \n",
       "\n",
       "                                           ICD9_CODE  \\\n",
       "0  ['42843', '41071', '5990', '4275', '5849', '50...   \n",
       "1  ['5781', '4280', '78039', '41401', '412', 'V45...   \n",
       "2  ['4241', '42843', '2761', '5849', '3342', '414...   \n",
       "3  ['53140', '2800', '4280', '53501', '25000', '4...   \n",
       "4  ['80600', '5849', '5990', '42731', '4280', '41...   \n",
       "\n",
       "                    DIAGNOSIS  \n",
       "0    CONGESTIVE HEART FAILURE  \n",
       "1      GASTROINTESTINAL BLEED  \n",
       "2                  CHEST PAIN  \n",
       "3  R/O GASTROINTESTINAL BLEED  \n",
       "4           SYNCOPE;TELEMETRY  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_extracted = []\n",
    "for had in hadm_id_extracted:\n",
    "    notes_extracted.append(df[df['HADM_ID'] == had].TEXT.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_extracted_cleaned = []\n",
    "original_note_list = []\n",
    "for note in notes_extracted:\n",
    "    original_note, cleaned_note, cleaned_note_splitted = NotesCleaning().clean_note_and_remove_abbreviations(note, abbreviations)\n",
    "    notes_extracted_cleaned.append(cleaned_note_splitted)\n",
    "    original_note_list.append(original_note)\n",
    "\n",
    "notes_extracted = notes_extracted_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_similar_substring(\n",
    "        embedding_relation,\n",
    "        token,\n",
    "        window_size,\n",
    "        model,\n",
    "        k,\n",
    "    ):\n",
    "        all_similarity_substring = []\n",
    "        list_windows, embedding_windows = UtilsSimilarity().rolling_window_embedding(\n",
    "            token, window_size, model\n",
    "        )\n",
    "        \n",
    "\n",
    "        for window, embedding_window in zip(list_windows, embedding_windows):\n",
    "            similarity = UtilsSimilarity().compute_cosine_similarity(\n",
    "                embedding_window, embedding_relation\n",
    "            )\n",
    "            all_similarity_substring.append((similarity, window))\n",
    "\n",
    "        all_similarity_substring.sort(key=lambda x: x[0], reverse=True)\n",
    "        ans = []\n",
    "        for item in all_similarity_substring[0:k]:\n",
    "            ans.append(WindowStore(item[0], item[1]))\n",
    "        return ans\n",
    "\n",
    "\n",
    "\n",
    "def extract_most_similar_part(\n",
    "        se,\n",
    "        relation_dict,\n",
    "        note,\n",
    "        tokens,\n",
    "        ICD_9,\n",
    "        word2vec_model,\n",
    "        window_size,\n",
    "        threshold,\n",
    "        k,\n",
    "    ):\n",
    "        best_similarity = []\n",
    "        relations = relation_dict.get(str(code), None)\n",
    "        best_similarity_codes = []\n",
    "        if relations:\n",
    "            # We can have multiple relation for each ICD-9 code\n",
    "            for relation in relations:\n",
    "                embedding_relation = (\n",
    "                    EmbeddingUtils().compute_embeddings(\n",
    "                        word2vec_model, relation\n",
    "                    )\n",
    "                )\n",
    "                best_window_substring = (\n",
    "                    get_k_most_similar_substring(\n",
    "                        embedding_relation,\n",
    "                        token,\n",
    "                        window_size,\n",
    "                        word2vec_model,\n",
    "                        k,\n",
    "                    )\n",
    "                )\n",
    "                for item in best_window_substring:\n",
    "                    item.add_relation(relation)\n",
    "                    # Here we store all the relation with the corresponding similarity value and the best substring we extracted\n",
    "                    best_similarity_codes.append(item)\n",
    "\n",
    "            # We compute the percentile to remove from the list the strings with a simialarity lower than this value\n",
    "            similarities = []\n",
    "            for item in best_similarity_codes:\n",
    "                similarities.append(item.similarity)\n",
    "            similarities = sorted(similarities)\n",
    "            percentile = np.percentile(similarities, threshold)\n",
    "            best_similarity_codes = [\n",
    "                item\n",
    "                for item in best_similarity_codes\n",
    "                    if item.similarity >= percentile\n",
    "            ]\n",
    "        \n",
    "        return best_similarity_codes\n",
    "\n",
    "def extract_lower_than_threshold(\n",
    "        se,\n",
    "        relation_dict,\n",
    "        note,\n",
    "        tokens,\n",
    "        ICD_9,\n",
    "        word2vec_model,\n",
    "        window_size,\n",
    "        threshold,\n",
    "        k,\n",
    "    ):\n",
    "        best_similarity = []\n",
    "        relations = relation_dict.get(str(code), None)\n",
    "        best_similarity_codes = []\n",
    "        if relations:\n",
    "            # We can have multiple relation for each ICD-9 code\n",
    "            for relation in relations:\n",
    "                embedding_relation = (\n",
    "                    EmbeddingUtils().compute_embeddings(\n",
    "                        word2vec_model, relation\n",
    "                    )\n",
    "                )\n",
    "                best_window_substring = (\n",
    "                    get_k_most_similar_substring(\n",
    "                        embedding_relation,\n",
    "                        token,\n",
    "                        window_size,\n",
    "                        word2vec_model,\n",
    "                        k,\n",
    "                    )\n",
    "                )\n",
    "                for item in best_window_substring:\n",
    "                    item.add_relation(relation)\n",
    "                    # Here we store all the relation with the corresponding similarity value and the best substring we extracted\n",
    "                    best_similarity_codes.append(item)\n",
    "\n",
    "            # We compute the percentile to remove from the list the strings with a simialarity lower than this value\n",
    "            similarities = []\n",
    "            for item in best_similarity_codes:\n",
    "                similarities.append(item.similarity)\n",
    "            similarities = sorted(similarities)\n",
    "            percentile = np.percentile(similarities, threshold)\n",
    "            best_similarity_codes = [\n",
    "                item\n",
    "                for item in best_similarity_codes\n",
    "                    if item.similarity < percentile\n",
    "            ]\n",
    "        \n",
    "        return best_similarity_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower than threashold\n",
    "\n",
    "threshold = 95\n",
    "k = 1\n",
    "results = []\n",
    "for code, id, hadm_id, note, token in zip(ICD_9_extracted, id_extracted, hadm_id_extracted, original_note_list, notes_extracted):\n",
    "    \n",
    "    best_substrings_finding_site = extract_lower_than_threshold(se, finding_site_dict, note, token, code, word2vec_model, 7, threshold, k)\n",
    "    best_substrings_due_to = extract_lower_than_threshold(se, due_to_dict, note, token, code, word2vec_model, 9, threshold, k)\n",
    "    best_substrings_associated_morphology = extract_lower_than_threshold(se, associated_morphology_dict, note, token, code, word2vec_model, 7, threshold, k)\n",
    "    best_substrings_description = extract_lower_than_threshold(se, description_dict, note, token, code, word2vec_model, 10, threshold, k)\n",
    "\n",
    "    for best_substring in best_substrings_finding_site:\n",
    "        converted_string, _, _ = se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Finding_site\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))\n",
    "    for best_substring in best_substrings_due_to:\n",
    "        converted_string, _, _= se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Due_to\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))\n",
    "    for best_substring in best_substrings_associated_morphology:\n",
    "        converted_string, _, _= se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Associated_morphology\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))\n",
    "    for best_substring in best_substrings_description:\n",
    "        converted_string, _, _ = se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Description\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 95\n",
    "k = 1\n",
    "results = []\n",
    "for code, id, hadm_id, note, token in zip(ICD_9_extracted, id_extracted, hadm_id_extracted, original_note_list, notes_extracted):\n",
    "    \n",
    "    best_substrings_finding_site = extract_most_similar_part(se, finding_site_dict, note, token, code, word2vec_model, 7, threshold, k)\n",
    "    best_substrings_due_to = extract_most_similar_part(se, due_to_dict, note, token, code, word2vec_model, 9, threshold, k)\n",
    "    best_substrings_associated_morphology = extract_most_similar_part(se, associated_morphology_dict, note, token, code, word2vec_model, 7, threshold, k)\n",
    "    best_substrings_description = extract_most_similar_part(se, description_dict, note, token, code, word2vec_model, 10, threshold, k)\n",
    "\n",
    "    for best_substring in best_substrings_finding_site:\n",
    "        converted_string, _, _ = se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Finding_site\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))\n",
    "    for best_substring in best_substrings_due_to:\n",
    "        converted_string, _, _= se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Due_to\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))\n",
    "    for best_substring in best_substrings_associated_morphology:\n",
    "        converted_string, _, _= se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Associated_morphology\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))\n",
    "    for best_substring in best_substrings_description:\n",
    "        converted_string, _, _ = se.convert_to_original_substring(note, best_substring.best_substring)\n",
    "        results.append((id, hadm_id, code, \"Description\", best_substring.best_substring, best_substring.similarity, best_substring.relation, converted_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_result = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = back_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe with all the extracted relations\n",
    "\n",
    "relations = []\n",
    "similarity = []\n",
    "substrings = []\n",
    "subject_ids = []\n",
    "hadm_ids = []\n",
    "relations_type = []\n",
    "icd9_list = []\n",
    "converted_strings = []\n",
    "for item in results:\n",
    "    subject_ids.append(item[0])\n",
    "    hadm_ids.append(item[1])\n",
    "    relations_type.append(item[3])\n",
    "    ICD_9 = item[2]\n",
    "    icd9_list.append(ICD_9)\n",
    "    relations.append(item[6])\n",
    "    similarity.append(item[5])\n",
    "    substrings.append(item[4])\n",
    "    converted_strings.append(item[7])\n",
    "\n",
    "list_tuples = list(zip(subject_ids, hadm_ids, icd9_list, relations_type, relations, similarity, substrings, converted_strings))\n",
    "\n",
    "results = pd.DataFrame(list_tuples, columns=['subject_ID', 'hadm_id', 'icd_9', 'relation_type', 'relation', 'similarity', 'extracted_substring', 'converted_string'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_ID</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_9</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>extracted_substring</th>\n",
       "      <th>converted_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>49322</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>airway structure</td>\n",
       "      <td>0.688396</td>\n",
       "      <td>[failure, post, upper, respiratory, infection,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>49322</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>chronic inflammatory morphology</td>\n",
       "      <td>0.788005</td>\n",
       "      <td>[infection, reactive, airways, disease, chroni...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>42731</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>cardiac conducting system structure</td>\n",
       "      <td>0.787525</td>\n",
       "      <td>[for, cardiac, catherterization, and, found, h...</td>\n",
       "      <td>for cardiac\\ncatherterization and found to hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>41401</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>atherosclerosis</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>[diagnosis, native, three, vessel, coronary, a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>41401</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>arteriolosclerosis</td>\n",
       "      <td>0.652033</td>\n",
       "      <td>[renal, failure, hypercoagulability, neck, hem...</td>\n",
       "      <td>renal failure\\nhypercoagulability\\nneck hemato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>2449</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>endocrine gonad</td>\n",
       "      <td>0.634076</td>\n",
       "      <td>[hypothyroidism, levoxyl, continued, thyroid, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>249</td>\n",
       "      <td>149546</td>\n",
       "      <td>56985</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>abdominal vascular structure</td>\n",
       "      <td>0.788083</td>\n",
       "      <td>[vessels, are, unremarkable, the, vertebral, a...</td>\n",
       "      <td>vessels are unremarkable.\\nThe vertebral\\nand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>249</td>\n",
       "      <td>149546</td>\n",
       "      <td>56985</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>intestinal structure</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>[the, junction, the, and, segments, this, repr...</td>\n",
       "      <td>the\\njunction of the M1 and M2 segments. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>249</td>\n",
       "      <td>149546</td>\n",
       "      <td>56985</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>vascular structure</td>\n",
       "      <td>0.713587</td>\n",
       "      <td>[the, and, segments, this, represents, thrombu...</td>\n",
       "      <td>the M1 and M2 segments. This represents a thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>249</td>\n",
       "      <td>149546</td>\n",
       "      <td>56985</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>gastrointestinal tract structure</td>\n",
       "      <td>0.744394</td>\n",
       "      <td>[the, setting, acute, gastrointestinal, bleedi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>249</td>\n",
       "      <td>149546</td>\n",
       "      <td>56985</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>angiodysplasia</td>\n",
       "      <td>0.779538</td>\n",
       "      <td>[hematochezia, likely, due, angiodysplasia, di...</td>\n",
       "      <td>hematochezia, anemia, and angina,\\nsent to MIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_ID  hadm_id  icd_9          relation_type  \\\n",
       "0          249   116935  49322           Finding_site   \n",
       "1          249   116935  49322  Associated_morphology   \n",
       "2          249   116935  42731           Finding_site   \n",
       "3          249   116935  41401  Associated_morphology   \n",
       "4          249   116935  41401  Associated_morphology   \n",
       "5          249   116935   2449           Finding_site   \n",
       "6          249   149546  56985           Finding_site   \n",
       "7          249   149546  56985           Finding_site   \n",
       "8          249   149546  56985           Finding_site   \n",
       "9          249   149546  56985           Finding_site   \n",
       "10         249   149546  56985  Associated_morphology   \n",
       "\n",
       "                               relation  similarity  \\\n",
       "0                      airway structure    0.688396   \n",
       "1       chronic inflammatory morphology    0.788005   \n",
       "2   cardiac conducting system structure    0.787525   \n",
       "3                       atherosclerosis    0.681517   \n",
       "4                    arteriolosclerosis    0.652033   \n",
       "5                       endocrine gonad    0.634076   \n",
       "6          abdominal vascular structure    0.788083   \n",
       "7                  intestinal structure    0.680800   \n",
       "8                    vascular structure    0.713587   \n",
       "9      gastrointestinal tract structure    0.744394   \n",
       "10                       angiodysplasia    0.779538   \n",
       "\n",
       "                                  extracted_substring  \\\n",
       "0   [failure, post, upper, respiratory, infection,...   \n",
       "1   [infection, reactive, airways, disease, chroni...   \n",
       "2   [for, cardiac, catherterization, and, found, h...   \n",
       "3   [diagnosis, native, three, vessel, coronary, a...   \n",
       "4   [renal, failure, hypercoagulability, neck, hem...   \n",
       "5   [hypothyroidism, levoxyl, continued, thyroid, ...   \n",
       "6   [vessels, are, unremarkable, the, vertebral, a...   \n",
       "7   [the, junction, the, and, segments, this, repr...   \n",
       "8   [the, and, segments, this, represents, thrombu...   \n",
       "9   [the, setting, acute, gastrointestinal, bleedi...   \n",
       "10  [hematochezia, likely, due, angiodysplasia, di...   \n",
       "\n",
       "                                     converted_string  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2   for cardiac\\ncatherterization and found to hav...  \n",
       "3                                                      \n",
       "4   renal failure\\nhypercoagulability\\nneck hemato...  \n",
       "5                                                      \n",
       "6   vessels are unremarkable.\\nThe vertebral\\nand ...  \n",
       "7   the\\njunction of the M1 and M2 segments. This ...  \n",
       "8   the M1 and M2 segments. This represents a thro...  \n",
       "9                                                      \n",
       "10  hematochezia, anemia, and angina,\\nsent to MIC...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/validation/result_sentence_extraction_lowe_than_threshold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/validation/conteggio.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_ID</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_9</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>extracted_substring</th>\n",
       "      <th>converted_string</th>\n",
       "      <th>Validazione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>49322</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>airway structure</td>\n",
       "      <td>0.688396</td>\n",
       "      <td>['failure' 'post' 'upper' 'respiratory' 'infec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>49322</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>chronic inflammatory morphology</td>\n",
       "      <td>0.788004</td>\n",
       "      <td>['infection' 'reactive' 'airways' 'disease' 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>42731</td>\n",
       "      <td>Finding_site</td>\n",
       "      <td>cardiac conducting system structure</td>\n",
       "      <td>0.787525</td>\n",
       "      <td>['for' 'cardiac' 'catherterization' 'and' 'fou...</td>\n",
       "      <td>for cardiac\\ncatherterization and found to hav...</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>41401</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>atherosclerosis</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>['diagnosis' 'native' 'three' 'vessel' 'corona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249</td>\n",
       "      <td>116935</td>\n",
       "      <td>41401</td>\n",
       "      <td>Associated_morphology</td>\n",
       "      <td>arteriolosclerosis</td>\n",
       "      <td>0.652033</td>\n",
       "      <td>['renal' 'failure' 'hypercoagulability' 'neck'...</td>\n",
       "      <td>renal failure\\nhypercoagulability\\nneck hemato...</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_ID  hadm_id  icd_9          relation_type  \\\n",
       "0         249   116935  49322           Finding_site   \n",
       "1         249   116935  49322  Associated_morphology   \n",
       "2         249   116935  42731           Finding_site   \n",
       "3         249   116935  41401  Associated_morphology   \n",
       "4         249   116935  41401  Associated_morphology   \n",
       "\n",
       "                              relation  similarity  \\\n",
       "0                     airway structure    0.688396   \n",
       "1      chronic inflammatory morphology    0.788004   \n",
       "2  cardiac conducting system structure    0.787525   \n",
       "3                      atherosclerosis    0.681517   \n",
       "4                   arteriolosclerosis    0.652033   \n",
       "\n",
       "                                 extracted_substring  \\\n",
       "0  ['failure' 'post' 'upper' 'respiratory' 'infec...   \n",
       "1  ['infection' 'reactive' 'airways' 'disease' 'c...   \n",
       "2  ['for' 'cardiac' 'catherterization' 'and' 'fou...   \n",
       "3  ['diagnosis' 'native' 'three' 'vessel' 'corona...   \n",
       "4  ['renal' 'failure' 'hypercoagulability' 'neck'...   \n",
       "\n",
       "                                    converted_string Validazione  \n",
       "0                                                NaN          FN  \n",
       "1                                                NaN          TN  \n",
       "2  for cardiac\\ncatherterization and found to hav...          TN  \n",
       "3                                                NaN          TN  \n",
       "4  renal failure\\nhypercoagulability\\nneck hemato...          TN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TN\") & (df.relation_type == \"Finding_site\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TP\") & (df.relation_type == \"Finding_site\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FP\") & (df.relation_type == \"Finding_site\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FN\") & (df.relation_type == \"Finding_site\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TN\") & (df.relation_type == \"Associated_morphology\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TP\") & (df.relation_type == \"Associated_morphology\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FP\") & (df.relation_type == \"Associated_morphology\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FN\") & (df.relation_type == \"Associated_morphology\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TN\") & (df.relation_type == \"Description\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TP\") & (df.relation_type == \"Description\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FN\") & (df.relation_type == \"Description\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FP\") & (df.relation_type == \"Description\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TN\") & (df.relation_type == \"Due_to\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"TP\") & (df.relation_type == \"Due_to\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FN\") & (df.relation_type == \"Due_to\")].Validazione.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Validazione == \"FP\") & (df.relation_type == \"Due_to\")].Validazione.count()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f14448ed29fac7011a5c1c71d341cfa5cd5137f17fb6a211a040db6ba0e6eca6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('.env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
